{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e4db57",
   "metadata": {},
   "source": [
    "Credits for this code to:\n",
    "- Pierre Megret https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial/notebook\n",
    "\n",
    "The code is mainly based on his tutorial. <br>\n",
    "The gender bias measurements are done as before. <br>\n",
    "WEAT tests are performeds using wefe package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91ef77",
   "metadata": {},
   "source": [
    "# 0. Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc7b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # For data handling\n",
    "import spacy  # For preprocessing\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "import wefe\n",
    "from wefe.query import Query\n",
    "from wefe.utils import load_test_model\n",
    "from wefe.metrics import WEAT\n",
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dfe1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444810, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>raw_post</th>\n",
       "      <th>fem_all</th>\n",
       "      <th>male_all</th>\n",
       "      <th>training</th>\n",
       "      <th>ypred</th>\n",
       "      <th>female</th>\n",
       "      <th>fem_pronoun</th>\n",
       "      <th>male_pronoun</th>\n",
       "      <th>training_pronoun</th>\n",
       "      <th>ypred_pronoun</th>\n",
       "      <th>female_pronoun</th>\n",
       "      <th>time_latest</th>\n",
       "      <th>month_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>request-a-thread-to-be-deleted-here</td>\n",
       "      <td>The fires went out, and blank darkness fell. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.860989e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>request-a-thread-to-be-deleted-here</td>\n",
       "      <td>Mod here. The meaning of life is  max V(A(t))=...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.082022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.067608e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>request-a-thread-to-be-deleted-here</td>\n",
       "      <td>The facts established in the recent paper by W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.387353e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>request-a-thread-to-be-deleted-here</td>\n",
       "      <td>OBLANCHARD-assuming you are Olivier Blanchard ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.526144e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>about-ejmr</td>\n",
       "      <td>Q: Why should I visit this site? A: There is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.388843e-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 days</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_id  post_id                                topic  \\\n",
       "0         1        4  request-a-thread-to-be-deleted-here   \n",
       "1         1        5  request-a-thread-to-be-deleted-here   \n",
       "2         1        9  request-a-thread-to-be-deleted-here   \n",
       "3         1       11  request-a-thread-to-be-deleted-here   \n",
       "4         2        2                           about-ejmr   \n",
       "\n",
       "                                            raw_post  fem_all  male_all  \\\n",
       "0  The fires went out, and blank darkness fell. T...        0         7   \n",
       "1  Mod here. The meaning of life is  max V(A(t))=...        0         1   \n",
       "2  The facts established in the recent paper by W...        0         1   \n",
       "3  OBLANCHARD-assuming you are Olivier Blanchard ...        5         5   \n",
       "4  Q: Why should I visit this site? A: There is a...        1         0   \n",
       "\n",
       "   training     ypred  female  fem_pronoun  male_pronoun  training_pronoun  \\\n",
       "0       0.0  0.001674       0            0             7               0.0   \n",
       "1       1.0  0.082022       0            0             1               1.0   \n",
       "2       1.0  0.032163       0            0             0               NaN   \n",
       "3       NaN  0.000792       0            0             0               NaN   \n",
       "4       1.0  0.000008       1            0             0               NaN   \n",
       "\n",
       "   ypred_pronoun  female_pronoun time_latest  month_latest  \n",
       "0   1.860989e-04             0.0     2 hours           0.0  \n",
       "1   8.067608e-03             0.0     2 hours           0.0  \n",
       "2   2.387353e-02             NaN     2 hours           0.0  \n",
       "3   2.526144e-02             NaN     2 hours           0.0  \n",
       "4   2.388843e-12             NaN      6 days           0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/alicewu_posts/gendered_posts.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb8db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototyping on subset of the posts\n",
    "subset = df.iloc[0:1000]\n",
    "merged_text = subset['raw_post'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c18ddd",
   "metadata": {},
   "source": [
    "# 1. Preprocess the posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bceced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: setuptools in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (58.1.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.22.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Installing English language\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53fb6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spacy instance\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.max_length = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e6acb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to sentenize the posts: 0.12 mins\n"
     ]
    }
   ],
   "source": [
    "# Break the posts into seperate sentences\n",
    "\n",
    "t = time()\n",
    "\n",
    "doc = nlp(merged_text)\n",
    "sents = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "print('Time to sentenize the posts: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5972631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all posts in the dataset\n",
    "\n",
    "t = time()\n",
    "\n",
    "lower_index = 0\n",
    "sents_store = list()\n",
    "\n",
    "for upper_index in range(0, 440000, 10000):\n",
    "    print(\"Processing row #: \", upper_index)\n",
    "    subset = df.iloc[lower_index:upper_index]\n",
    "    merged_text = subset['raw_post'].str.cat(sep=' ')\n",
    "    \n",
    "    t = time()\n",
    "    doc = nlp(merged_text)\n",
    "    sents = [sent.text.strip() for sent in doc.sents]\n",
    "    print('Time to sentenize the book: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "    \n",
    "    sents_store.append(sents)\n",
    "    lower_index = upper_index\n",
    "    \n",
    "print('Time to process the posts: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the sentences\n",
    "from functools import reduce\n",
    "sents = reduce(lambda xs, ys: xs + ys, sents_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab757b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed posts\n",
    "import pickle\n",
    "with open(\"forum_posts.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(sents, fp)\n",
    "    \n",
    "# with open(\"test\", \"rb\") as fp:   # Unpickling\n",
    "#     b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fe2d898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"forum_posts.pkl\", \"rb\") as fp:   # Unpickling\n",
    "    sents = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e3aa01",
   "metadata": {},
   "source": [
    "# 2. Clean the posts with Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7635efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "#loading the english language small model of spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1995a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing pronouns from spacy stopwords\n",
    "nlp.Defaults.stop_words -= {'he', 'his', 'him', 'himself', 'male', 'man', 'men'}\n",
    "nlp.Defaults.stop_words -= {'she', 'her', 'herself', 'female', 'woman', 'women'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b494972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624316c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes non-alphabetic characters:\n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(sent)).lower() for sent in sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6166bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 0.19 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c40a3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Nones and duplicates\n",
    "txt = list(set(filter(None, txt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a89d27",
   "metadata": {},
   "source": [
    "# 3. Identify bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c338468",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [sent.split() for sent in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e6e43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:24:36: collecting all words and their counts\n",
      "INFO - 19:24:36: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 19:24:36: collected 19257 token types (unigram + bigrams) from a corpus of 18233 words and 2297 sentences\n",
      "INFO - 19:24:36: merged Phrases<19257 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 19:24:36: Phrases lifecycle event {'msg': 'built Phrases<19257 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.04s', 'datetime': '2022-06-21T19:24:36.781420', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610a885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:24:38: exporting phrases from Phrases<19257 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 19:24:38: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<0 phrases, min_count=30, threshold=10.0> from Phrases<19257 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.05s', 'datetime': '2022-06-21T19:24:38.409196', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d7993a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'yeah',\n",
       " 'weird',\n",
       " 'thought',\n",
       " 'relationship',\n",
       " 'mean',\n",
       " 'boring',\n",
       " 'life']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92720a7",
   "metadata": {},
   "source": [
    "## 3.2 Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387d8b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4763"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473a9543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['his', 'like', 'guy', 'good', 'woman', 'think', 'paper', 'he', 'know', 's']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edebaf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq['she']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422055cf",
   "metadata": {},
   "source": [
    "# 4. Train the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4464f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998d48f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:24:46: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2022-06-21T19:24:46.512550', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=10,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=25,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f7414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:24:47: collecting all words and their counts\n",
      "INFO - 19:24:47: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 19:24:47: collected 4763 word types from a corpus of 18233 raw words and 2297 sentences\n",
      "INFO - 19:24:47: Creating a fresh vocabulary\n",
      "INFO - 19:24:47: Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 381 unique words (8.00% of original 4763, drops 4382)', 'datetime': '2022-06-21T19:24:47.347589', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 19:24:47: Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 9084 word corpus (49.82% of original 18233, drops 9149)', 'datetime': '2022-06-21T19:24:47.348769', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 19:24:47: deleting the raw counts dictionary of 4763 items\n",
      "INFO - 19:24:47: sample=6e-05 downsamples 381 most-common words\n",
      "INFO - 19:24:47: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1497.1579917904385 word corpus (16.5%% of prior 9084)', 'datetime': '2022-06-21T19:24:47.359010', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 19:24:47: estimated required memory for 381 words and 300 dimensions: 1104900 bytes\n",
      "INFO - 19:24:47: resetting layer weights\n",
      "INFO - 19:24:47: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-21T19:24:47.374968', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "616bccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:24:47: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 381 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=25 window=2 shrink_windows=True', 'datetime': '2022-06-21T19:24:47.707155', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO - 19:24:47: EPOCH 0: training on 18233 raw words (1432 effective words) took 0.0s, 44478 effective words/s\n",
      "INFO - 19:24:47: EPOCH 1: training on 18233 raw words (1536 effective words) took 0.0s, 49444 effective words/s\n",
      "INFO - 19:24:47: EPOCH 2: training on 18233 raw words (1481 effective words) took 0.0s, 49460 effective words/s\n",
      "INFO - 19:24:47: EPOCH 3: training on 18233 raw words (1530 effective words) took 0.0s, 47011 effective words/s\n",
      "INFO - 19:24:47: EPOCH 4: training on 18233 raw words (1477 effective words) took 0.0s, 50490 effective words/s\n",
      "INFO - 19:24:47: EPOCH 5: training on 18233 raw words (1536 effective words) took 0.0s, 60947 effective words/s\n",
      "INFO - 19:24:47: EPOCH 6: training on 18233 raw words (1482 effective words) took 0.0s, 47175 effective words/s\n",
      "INFO - 19:24:48: EPOCH 7: training on 18233 raw words (1466 effective words) took 0.0s, 62724 effective words/s\n",
      "INFO - 19:24:48: EPOCH 8: training on 18233 raw words (1484 effective words) took 0.0s, 54253 effective words/s\n",
      "INFO - 19:24:48: EPOCH 9: training on 18233 raw words (1527 effective words) took 0.0s, 66167 effective words/s\n",
      "INFO - 19:24:48: EPOCH 10: training on 18233 raw words (1520 effective words) took 0.0s, 70982 effective words/s\n",
      "INFO - 19:24:48: EPOCH 11: training on 18233 raw words (1470 effective words) took 0.0s, 67342 effective words/s\n",
      "INFO - 19:24:48: EPOCH 12: training on 18233 raw words (1507 effective words) took 0.1s, 29619 effective words/s\n",
      "INFO - 19:24:48: EPOCH 13: training on 18233 raw words (1497 effective words) took 0.0s, 54295 effective words/s\n",
      "INFO - 19:24:48: EPOCH 14: training on 18233 raw words (1492 effective words) took 0.0s, 62298 effective words/s\n",
      "INFO - 19:24:48: EPOCH 15: training on 18233 raw words (1469 effective words) took 0.0s, 69842 effective words/s\n",
      "INFO - 19:24:48: EPOCH 16: training on 18233 raw words (1446 effective words) took 0.0s, 63955 effective words/s\n",
      "INFO - 19:24:48: EPOCH 17: training on 18233 raw words (1543 effective words) took 0.0s, 74427 effective words/s\n",
      "INFO - 19:24:48: EPOCH 18: training on 18233 raw words (1483 effective words) took 0.0s, 56955 effective words/s\n",
      "INFO - 19:24:48: EPOCH 19: training on 18233 raw words (1502 effective words) took 0.0s, 68030 effective words/s\n",
      "INFO - 19:24:48: EPOCH 20: training on 18233 raw words (1493 effective words) took 0.0s, 66727 effective words/s\n",
      "INFO - 19:24:48: EPOCH 21: training on 18233 raw words (1486 effective words) took 0.0s, 70970 effective words/s\n",
      "INFO - 19:24:48: EPOCH 22: training on 18233 raw words (1478 effective words) took 0.0s, 74580 effective words/s\n",
      "INFO - 19:24:48: EPOCH 23: training on 18233 raw words (1570 effective words) took 0.0s, 79629 effective words/s\n",
      "INFO - 19:24:48: EPOCH 24: training on 18233 raw words (1468 effective words) took 0.0s, 67992 effective words/s\n",
      "INFO - 19:24:48: EPOCH 25: training on 18233 raw words (1474 effective words) took 0.0s, 74901 effective words/s\n",
      "INFO - 19:24:48: EPOCH 26: training on 18233 raw words (1543 effective words) took 0.0s, 73099 effective words/s\n",
      "INFO - 19:24:48: EPOCH 27: training on 18233 raw words (1480 effective words) took 0.0s, 68974 effective words/s\n",
      "INFO - 19:24:48: EPOCH 28: training on 18233 raw words (1473 effective words) took 0.0s, 71780 effective words/s\n",
      "INFO - 19:24:48: EPOCH 29: training on 18233 raw words (1496 effective words) took 0.0s, 72853 effective words/s\n",
      "INFO - 19:24:48: Word2Vec lifecycle event {'msg': 'training on 546990 raw words (44841 effective words) took 1.0s, 43702 effective words/s', 'datetime': '2022-06-21T19:24:48.734970', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e080552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 19:24:48: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "178ede57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('find', 0.9997744560241699),\n",
       " ('play', 0.9997660517692566),\n",
       " ('paper', 0.9997659921646118),\n",
       " ('publish', 0.9997531771659851),\n",
       " ('job', 0.9997520446777344),\n",
       " ('wife', 0.9997513294219971),\n",
       " ('chinese', 0.999751091003418),\n",
       " ('html', 0.9997481107711792),\n",
       " ('r', 0.9997481107711792),\n",
       " ('bro', 0.9997469186782837)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed755db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thread', 0.9997735619544983),\n",
       " ('html', 0.9997717142105103),\n",
       " ('her', 0.9997581243515015),\n",
       " ('show', 0.9997564554214478),\n",
       " ('tenure', 0.9997557401657104),\n",
       " ('male', 0.9997535943984985),\n",
       " ('professor', 0.9997529983520508),\n",
       " ('economic', 0.9997521638870239),\n",
       " ('level', 0.999751627445221),\n",
       " ('research', 0.9997478127479553)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e666bcf",
   "metadata": {},
   "source": [
    "# 5. Measuring Gender Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad2bf6",
   "metadata": {},
   "source": [
    "## 5.1 Defining target and attribute words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a94b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_pronouns = ['her', 'herself', 'she']\n",
    "female_names = ['amy', 'athey', 'duflo', 'elizabeth', 'emily', 'hilary',\n",
    "                'hillary', 'jane', 'jennifer', 'jessica', 'maria', 'mary',\n",
    "                'nancy', 'reinhart', 'sarah', 'susan', 'yellen']\n",
    "female_identity = ['female', 'females', 'ladies', 'lady', 'woman', 'women']\n",
    "female_miscellaneous = ['bietches', 'bitch', 'bitches', 'broette', 'broettes', 'chick', 'chicks',\n",
    "                'daughter', 'daughters', 'gf', 'girl', 'girlfriend', 'girlfriends',\n",
    "                'girls', 'mom', 'moms', 'mother', 'mothers', 'sister', 'sisters', 'wife',\n",
    "                'wives']\n",
    "\n",
    "female_words = female_pronouns + female_names + female_identity + female_miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e76eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns = ['he', 'him', 'himself', 'his']\n",
    "male_names = ['acemoglu', 'adam', 'akerlof', 'alan', 'albert', 'alexander', 'allen', 'andrew', 'angrist', 'arthur',\n",
    "'autor', 'baker', 'barro', 'becker', 'ben', 'benjamin', 'bernanke', 'berry', 'blanchard', 'bob', 'borjas']\n",
    "male_identity = ['male', 'males', 'man', 'men']\n",
    "male_miscellaneous = ['bf', 'boy', 'boyfriend', 'boys', 'bro', 'bros', 'brother', 'brothers', 'dad', 'daddy',\n",
    "'dude', 'dudes', 'father', 'fathers', 'gentleman', 'grandfather', 'guy', 'guys',\n",
    "'husband', 'husbands', 'papa', 'sir', 'son', 'sons', 'uncle']\n",
    "\n",
    "male_words = male_pronouns + male_names + male_identity + male_miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "409700e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names_full = ['acemoglu', 'adam', 'akerlof', 'alan', 'albert', 'alexander', 'allen', 'andrew', 'angrist', 'arthur',\n",
    "'autor', 'baker', 'barro', 'becker', 'ben', 'benjamin', 'bernanke', 'berry', 'blanchard', 'bob', 'borjas',\n",
    "'brian', 'campbell', 'carl', 'carlos', 'charlie', 'chetty', 'chris', 'christopher', 'cochrane', 'colin',\n",
    "'cowen', 'daniel', 'daron', 'david', 'deaton', 'delong', 'duffie', 'edward', 'eric', 'eugene', 'fama',\n",
    "'frank', 'frey', 'friedman', 'friedman', 'gary', 'george', 'gintis', 'glaeser', 'gordon', 'greene',\n",
    "'greg', 'gregory', 'hansen', 'harry', 'hayashi', 'hayek', 'heckman', 'henderson', 'henry', 'imben',\n",
    "'jack', 'james', 'jason', 'je', 'jerey', 'jeremy', 'jimmy', 'joe', 'john', 'jon', 'jonathan', 'jose',\n",
    "'joseph', 'justin', 'kehoe', 'ken', 'kenneth', 'kevin', 'krueger', 'kruggles', 'krugman', 'krugmans',\n",
    "'larry', 'lars', 'levine', 'levitt', 'lucas', 'mankiw', 'mark', 'martin', 'matt', 'matthew', 'michael',\n",
    "'mike', 'miller', 'milton', 'murphy', 'myerson', 'neumann', 'nicholas', 'nick', 'noah', 'parag', 'pat',\n",
    "'pathak', 'patrick', 'paul', 'perez', 'peter', 'phil', 'philip', 'phillips', 'pierre', 'piketty', 'pikettys',\n",
    "'powell', 'prescott', 'rabin', 'raj', 'ravikumar', 'ricardo', 'richard', 'robert', 'roberts', 'robinson',\n",
    "'roger', 'rogo', 'ron', 'roth', 'rubin', 'rubinstein', 'russ', 'rust', 'ryan', 'saez', 'sam', 'sargent', 'shapiro',\n",
    "'shiller', 'shleifer', 'simon', 'sims', 'stephen', 'steve', 'steven', 'stiglitz', 'summers', 'terry', 'thaler',\n",
    "'thomas', 'tim', 'tirole', 'tom', 'tony', 'victor', 'walker', 'wallace', 'walter', 'werning', 'williamson',\n",
    "'wolfer', 'woodford', 'wooldridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7da5e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Gender Classifiers\n",
    "male_words = ['he', 'his', 'him', 'himself', 'male', 'man', 'men']\n",
    "female_words = ['she', 'her', 'herself', 'female', 'woman', 'women']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72547c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Academic/Professional\n",
    "economics = ['economics', 'macro', 'empirical','qje', 'keynesian']\n",
    "academic_general = ['research', 'papers','tenure', 'teaching', 'professor']\n",
    "professional = ['career', 'interview', 'payrolls', 'placement', 'recruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea1a2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal/Physical\n",
    "personal_information = ['family','married', 'kids', 'relationship','lifestyle']\n",
    "physical_attributes = ['beautiful', 'handsome', 'attractive', 'body','fat']\n",
    "gender_related = ['gender', 'feminine', 'masculine', 'sexist', 'sexual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60469421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swear Words\n",
    "swear = ['shit', 'wtf', 'asshole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1e94e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intellectual\n",
    "intellectual_positive = ['intelligent', 'creative','competent']\n",
    "intellectual_neutral = ['brain', 'iq', 'ability']\n",
    "intellectual_negative = ['dumb','ignorant','incompetent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9af95126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous\n",
    "emotion_feelings = ['happy','depressing']\n",
    "others = ['years', 'places', 'everything']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c8113",
   "metadata": {},
   "source": [
    "## 5.2 Defining functions for gender bias measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d37dffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_attr_words(vectors, word_list1, word_list2):\n",
    "    words_to_average1 = list()\n",
    "    words_to_average2 = list()\n",
    "    \n",
    "    for word1 in word_list1:\n",
    "        try:\n",
    "            words_to_average1.append(vectors[word1])\n",
    "        except:\n",
    "            print(\"Word is not present: \", word1)\n",
    "            \n",
    "    for word2 in word_list2:\n",
    "        try:\n",
    "            words_to_average2.append(vectors[word2])\n",
    "        except:\n",
    "            print(\"Word is not present: \", word2)\n",
    "            \n",
    "    #print(\"The length of average word list 1: \", len(words_to_average1))\n",
    "    #print(\"The length of average word list 2: \", len(words_to_average2))\n",
    "    \n",
    "    averaged_words1 = np.array(words_to_average1).mean(axis=0)\n",
    "    averaged_words2 = np.array(words_to_average2).mean(axis=0)\n",
    "\n",
    "    \n",
    "    return averaged_words1, averaged_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "310b54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a2f5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_between_vectors(vec1, vec2, distype = 'norm'):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea43e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relative_norm_distance(vectors, male_word_list, female_word_list, neutral_words):\n",
    "    \n",
    "    male_avg_vec, female_avg_vec = average_attr_words(vectors, male_word_list, female_word_list)\n",
    "    \n",
    "    list_rel_norm_dist = []\n",
    "    for word in neutral_words:\n",
    "        try:\n",
    "            rel_norm_dist = calc_distance_between_vectors(vectors[word], male_avg_vec) - \\\n",
    "                            calc_distance_between_vectors(vectors[word], female_avg_vec)\n",
    "            list_rel_norm_dist.append(rel_norm_dist)\n",
    "        except:\n",
    "            print(\"Word is not present: \", word)\n",
    "    return np.array(list_rel_norm_dist).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162b73",
   "metadata": {},
   "source": [
    "# 6. Gender Bias measurement following Garg et al. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e92c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_of_words = [economics, academic_general, professional, personal_information, physical_attributes, \n",
    "                  gender_related, intellectual_positive, intellectual_neutral, intellectual_negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa0d9d",
   "metadata": {},
   "source": [
    "## On gender pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f83c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is not present:  him\n",
      "Word is not present:  herself\n",
      "Word is not present:  papers\n",
      "Word is not present:  teaching\n",
      "Word is not present:  interview\n",
      "Word is not present:  payrolls\n",
      "Word is not present:  placement\n",
      "Word is not present:  recruit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0006682966"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_relative_norm_distance(w2v_model.wv, male_pronouns, female_pronouns, academic_general + professional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cd74a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is not present:  him\n",
      "Word is not present:  herself\n",
      "Word is not present:  married\n",
      "Word is not present:  kids\n",
      "Word is not present:  relationship\n",
      "Word is not present:  lifestyle\n",
      "Word is not present:  beautiful\n",
      "Word is not present:  handsome\n",
      "Word is not present:  attractive\n",
      "Word is not present:  fat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00025895052"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_relative_norm_distance(w2v_model.wv, male_pronouns, female_pronouns, personal_information + physical_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27562d0",
   "metadata": {},
   "source": [
    "## On gender names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cacb602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is not present:  acemoglu\n",
      "Word is not present:  adam\n",
      "Word is not present:  akerlof\n",
      "Word is not present:  alan\n",
      "Word is not present:  albert\n",
      "Word is not present:  alexander\n",
      "Word is not present:  allen\n",
      "Word is not present:  andrew\n",
      "Word is not present:  angrist\n",
      "Word is not present:  arthur\n",
      "Word is not present:  autor\n",
      "Word is not present:  baker\n",
      "Word is not present:  barro\n",
      "Word is not present:  becker\n",
      "Word is not present:  ben\n",
      "Word is not present:  benjamin\n",
      "Word is not present:  bernanke\n",
      "Word is not present:  berry\n",
      "Word is not present:  blanchard\n",
      "Word is not present:  bob\n",
      "Word is not present:  borjas\n",
      "Word is not present:  amy\n",
      "Word is not present:  athey\n",
      "Word is not present:  duflo\n",
      "Word is not present:  elizabeth\n",
      "Word is not present:  emily\n",
      "Word is not present:  hilary\n",
      "Word is not present:  hillary\n",
      "Word is not present:  jane\n",
      "Word is not present:  jennifer\n",
      "Word is not present:  jessica\n",
      "Word is not present:  maria\n",
      "Word is not present:  mary\n",
      "Word is not present:  nancy\n",
      "Word is not present:  reinhart\n",
      "Word is not present:  sarah\n",
      "Word is not present:  susan\n",
      "Word is not present:  yellen\n",
      "Word is not present:  economics\n",
      "Word is not present:  macro\n",
      "Word is not present:  empirical\n",
      "Word is not present:  qje\n",
      "Word is not present:  keynesian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/142448549.py:20: RuntimeWarning: Mean of empty slice.\n",
      "  averaged_words1 = np.array(words_to_average1).mean(axis=0)\n",
      "/Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/142448549.py:21: RuntimeWarning: Mean of empty slice.\n",
      "  averaged_words2 = np.array(words_to_average2).mean(axis=0)\n",
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/3291762599.py:13: RuntimeWarning: Mean of empty slice.\n",
      "  return np.array(list_rel_norm_dist).mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_relative_norm_distance(w2v_model.wv, male_names, female_names, economics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9f419cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is not present:  acemoglu\n",
      "Word is not present:  adam\n",
      "Word is not present:  akerlof\n",
      "Word is not present:  alan\n",
      "Word is not present:  albert\n",
      "Word is not present:  alexander\n",
      "Word is not present:  allen\n",
      "Word is not present:  andrew\n",
      "Word is not present:  angrist\n",
      "Word is not present:  arthur\n",
      "Word is not present:  autor\n",
      "Word is not present:  baker\n",
      "Word is not present:  barro\n",
      "Word is not present:  becker\n",
      "Word is not present:  ben\n",
      "Word is not present:  benjamin\n",
      "Word is not present:  bernanke\n",
      "Word is not present:  berry\n",
      "Word is not present:  blanchard\n",
      "Word is not present:  bob\n",
      "Word is not present:  borjas\n",
      "Word is not present:  brian\n",
      "Word is not present:  campbell\n",
      "Word is not present:  carl\n",
      "Word is not present:  carlos\n",
      "Word is not present:  charlie\n",
      "Word is not present:  chetty\n",
      "Word is not present:  chris\n",
      "Word is not present:  christopher\n",
      "Word is not present:  cochrane\n",
      "Word is not present:  colin\n",
      "Word is not present:  cowen\n",
      "Word is not present:  daniel\n",
      "Word is not present:  daron\n",
      "Word is not present:  deaton\n",
      "Word is not present:  delong\n",
      "Word is not present:  duffie\n",
      "Word is not present:  edward\n",
      "Word is not present:  eric\n",
      "Word is not present:  eugene\n",
      "Word is not present:  fama\n",
      "Word is not present:  frank\n",
      "Word is not present:  frey\n",
      "Word is not present:  friedman\n",
      "Word is not present:  friedman\n",
      "Word is not present:  gary\n",
      "Word is not present:  george\n",
      "Word is not present:  gintis\n",
      "Word is not present:  glaeser\n",
      "Word is not present:  gordon\n",
      "Word is not present:  greene\n",
      "Word is not present:  greg\n",
      "Word is not present:  gregory\n",
      "Word is not present:  hansen\n",
      "Word is not present:  harry\n",
      "Word is not present:  hayek\n",
      "Word is not present:  heckman\n",
      "Word is not present:  henderson\n",
      "Word is not present:  henry\n",
      "Word is not present:  imben\n",
      "Word is not present:  jack\n",
      "Word is not present:  james\n",
      "Word is not present:  jason\n",
      "Word is not present:  je\n",
      "Word is not present:  jerey\n",
      "Word is not present:  jeremy\n",
      "Word is not present:  jimmy\n",
      "Word is not present:  john\n",
      "Word is not present:  jon\n",
      "Word is not present:  jonathan\n",
      "Word is not present:  jose\n",
      "Word is not present:  joseph\n",
      "Word is not present:  justin\n",
      "Word is not present:  kehoe\n",
      "Word is not present:  ken\n",
      "Word is not present:  kenneth\n",
      "Word is not present:  kevin\n",
      "Word is not present:  krueger\n",
      "Word is not present:  kruggles\n",
      "Word is not present:  krugman\n",
      "Word is not present:  krugmans\n",
      "Word is not present:  larry\n",
      "Word is not present:  lars\n",
      "Word is not present:  levine\n",
      "Word is not present:  levitt\n",
      "Word is not present:  lucas\n",
      "Word is not present:  mankiw\n",
      "Word is not present:  mark\n",
      "Word is not present:  martin\n",
      "Word is not present:  matt\n",
      "Word is not present:  matthew\n",
      "Word is not present:  michael\n",
      "Word is not present:  mike\n",
      "Word is not present:  miller\n",
      "Word is not present:  milton\n",
      "Word is not present:  murphy\n",
      "Word is not present:  myerson\n",
      "Word is not present:  neumann\n",
      "Word is not present:  nicholas\n",
      "Word is not present:  nick\n",
      "Word is not present:  noah\n",
      "Word is not present:  parag\n",
      "Word is not present:  pat\n",
      "Word is not present:  pathak\n",
      "Word is not present:  patrick\n",
      "Word is not present:  paul\n",
      "Word is not present:  perez\n",
      "Word is not present:  peter\n",
      "Word is not present:  phil\n",
      "Word is not present:  philip\n",
      "Word is not present:  phillips\n",
      "Word is not present:  pierre\n",
      "Word is not present:  piketty\n",
      "Word is not present:  pikettys\n",
      "Word is not present:  powell\n",
      "Word is not present:  prescott\n",
      "Word is not present:  rabin\n",
      "Word is not present:  raj\n",
      "Word is not present:  ravikumar\n",
      "Word is not present:  ricardo\n",
      "Word is not present:  richard\n",
      "Word is not present:  robert\n",
      "Word is not present:  roberts\n",
      "Word is not present:  robinson\n",
      "Word is not present:  roger\n",
      "Word is not present:  rogo\n",
      "Word is not present:  ron\n",
      "Word is not present:  roth\n",
      "Word is not present:  rubin\n",
      "Word is not present:  rubinstein\n",
      "Word is not present:  russ\n",
      "Word is not present:  rust\n",
      "Word is not present:  ryan\n",
      "Word is not present:  saez\n",
      "Word is not present:  sam\n",
      "Word is not present:  sargent\n",
      "Word is not present:  shapiro\n",
      "Word is not present:  shiller\n",
      "Word is not present:  shleifer\n",
      "Word is not present:  simon\n",
      "Word is not present:  sims\n",
      "Word is not present:  stephen\n",
      "Word is not present:  steven\n",
      "Word is not present:  stiglitz\n",
      "Word is not present:  summers\n",
      "Word is not present:  terry\n",
      "Word is not present:  thaler\n",
      "Word is not present:  thomas\n",
      "Word is not present:  tim\n",
      "Word is not present:  tirole\n",
      "Word is not present:  tom\n",
      "Word is not present:  tony\n",
      "Word is not present:  victor\n",
      "Word is not present:  walker\n",
      "Word is not present:  wallace\n",
      "Word is not present:  walter\n",
      "Word is not present:  werning\n",
      "Word is not present:  williamson\n",
      "Word is not present:  wolfer\n",
      "Word is not present:  woodford\n",
      "Word is not present:  wooldridge\n",
      "Word is not present:  amy\n",
      "Word is not present:  athey\n",
      "Word is not present:  duflo\n",
      "Word is not present:  elizabeth\n",
      "Word is not present:  emily\n",
      "Word is not present:  hilary\n",
      "Word is not present:  hillary\n",
      "Word is not present:  jane\n",
      "Word is not present:  jennifer\n",
      "Word is not present:  jessica\n",
      "Word is not present:  maria\n",
      "Word is not present:  mary\n",
      "Word is not present:  nancy\n",
      "Word is not present:  reinhart\n",
      "Word is not present:  sarah\n",
      "Word is not present:  susan\n",
      "Word is not present:  yellen\n",
      "Word is not present:  papers\n",
      "Word is not present:  teaching\n",
      "Word is not present:  interview\n",
      "Word is not present:  payrolls\n",
      "Word is not present:  placement\n",
      "Word is not present:  recruit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/142448549.py:21: RuntimeWarning: Mean of empty slice.\n",
      "  averaged_words2 = np.array(words_to_average2).mean(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_relative_norm_distance(w2v_model.wv, male_names_full, female_names, academic_general + professional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9bcfa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is not present:  acemoglu\n",
      "Word is not present:  adam\n",
      "Word is not present:  akerlof\n",
      "Word is not present:  alan\n",
      "Word is not present:  albert\n",
      "Word is not present:  alexander\n",
      "Word is not present:  allen\n",
      "Word is not present:  andrew\n",
      "Word is not present:  angrist\n",
      "Word is not present:  arthur\n",
      "Word is not present:  autor\n",
      "Word is not present:  baker\n",
      "Word is not present:  barro\n",
      "Word is not present:  becker\n",
      "Word is not present:  ben\n",
      "Word is not present:  benjamin\n",
      "Word is not present:  bernanke\n",
      "Word is not present:  berry\n",
      "Word is not present:  blanchard\n",
      "Word is not present:  bob\n",
      "Word is not present:  borjas\n",
      "Word is not present:  amy\n",
      "Word is not present:  athey\n",
      "Word is not present:  duflo\n",
      "Word is not present:  elizabeth\n",
      "Word is not present:  emily\n",
      "Word is not present:  hilary\n",
      "Word is not present:  hillary\n",
      "Word is not present:  jane\n",
      "Word is not present:  jennifer\n",
      "Word is not present:  jessica\n",
      "Word is not present:  maria\n",
      "Word is not present:  mary\n",
      "Word is not present:  nancy\n",
      "Word is not present:  reinhart\n",
      "Word is not present:  sarah\n",
      "Word is not present:  susan\n",
      "Word is not present:  yellen\n",
      "Word is not present:  married\n",
      "Word is not present:  kids\n",
      "Word is not present:  relationship\n",
      "Word is not present:  lifestyle\n",
      "Word is not present:  beautiful\n",
      "Word is not present:  handsome\n",
      "Word is not present:  attractive\n",
      "Word is not present:  fat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/142448549.py:20: RuntimeWarning: Mean of empty slice.\n",
      "  averaged_words1 = np.array(words_to_average1).mean(axis=0)\n",
      "/var/folders/6m/7qj3x7j16pqbzfycpphbz9z40000gn/T/ipykernel_33101/142448549.py:21: RuntimeWarning: Mean of empty slice.\n",
      "  averaged_words2 = np.array(words_to_average2).mean(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_relative_norm_distance(w2v_model.wv, male_names, female_names, personal_information + physical_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57ffc3",
   "metadata": {},
   "source": [
    "# 7. WEAT test by Caliscan et al. (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eede844",
   "metadata": {},
   "source": [
    "## 7.1 Check baseline bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb3c7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:25:37: loading KeyedVectors object from /Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages/wefe/datasets/data/test_model.kv\n",
      "INFO - 19:25:37: setting ignored attribute vectors_norm to None\n",
      "INFO - 19:25:37: KeyedVectors lifecycle event {'fname': '/Users/bryskulov/Desktop/QEM Barcelona/Thesis/thesis-gender-bias/env/lib/python3.9/site-packages/wefe/datasets/data/test_model.kv', 'datetime': '2022-06-21T19:25:37.964800', 'gensim': '4.2.0', 'python': '3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 17:02:14) \\n[Clang 6.0 (clang-600.0.57)]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# load the test model\n",
    "model = load_test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96ecfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "family = [\"home\", \"parents\", \"children\", \"family\", \"cousin\", \"marriage\",\n",
    "         \"wedding\"]\n",
    "career = [\"executive\", \"management\", \"professional\", \"corporation\", \"salary\",\n",
    "         \"office\", \"business\", \"career\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33ad05ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male Terms wrt Family and Career',\n",
       " 'result': 0.44263947810811377,\n",
       " 'weat': 0.44263947810811377,\n",
       " 'effect_size': 0.4196374793469268,\n",
       " 'p_value': 0.2024797520247975}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the query\n",
    "query = Query(\n",
    "    target_sets=[\n",
    "        [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\",\n",
    "         \"daughter\"],\n",
    "        [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"],\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        family, career\n",
    "    ],\n",
    "    target_sets_names=[\"Female terms\", \"Male Terms\"],\n",
    "    attribute_sets_names=[\"Family\", \"Career\"],\n",
    ")\n",
    "\n",
    "\n",
    "# instance the metric and run the query\n",
    "WEAT().run_query(query, model, calculate_p_value=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09db88",
   "metadata": {},
   "source": [
    "## 7.2 Running WEAT tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "638a5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "wefe_model = WordEmbeddingModel(w2v_model.wv, 'AliceWu model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f621d1",
   "metadata": {},
   "source": [
    "### 7.2.1 Gender pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "03f09a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the query\n",
    "query_pronouns = Query(\n",
    "    target_sets=[\n",
    "        female_pronouns,\n",
    "        male_pronouns,\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        academic_general + professional,\n",
    "        personal_information + physical_attributes\n",
    "    ],\n",
    "    target_sets_names=[\"Female pronouns\", \"Male pronouns\"],\n",
    "    attribute_sets_names=[\"Professional\", \"Personal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c3ebdf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female pronouns and Male pronouns wrt Professional and Personal',\n",
       " 'result': -0.7228623523066441,\n",
       " 'weat': -0.7228623523066441,\n",
       " 'effect_size': -1.8917259145115586,\n",
       " 'p_value': 0.9875173370319001}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the metric and run the query\n",
    "WEAT().run_query(query_pronouns, wefe_model, normalize=True, calculate_p_value=True, \n",
    "                 p_value_method=\"approximate\", p_value_iterations=10000, lost_vocabulary_threshold=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09991176",
   "metadata": {},
   "source": [
    "### 7.2.2 Gender names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a46fa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the query\n",
    "query_names = Query(\n",
    "    target_sets=[\n",
    "        female_names,\n",
    "        male_names,\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        academic_general + professional,\n",
    "        personal_information + physical_attributes\n",
    "    ],\n",
    "    target_sets_names=[\"Female Names\", \"Male Names\"],\n",
    "    attribute_sets_names=[\"Professional\", \"Personal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "37b1aeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female Names and Male Names wrt Professional and Personal',\n",
       " 'result': -1.7645896530399718,\n",
       " 'weat': -1.7645896530399718,\n",
       " 'effect_size': -1.2123690220188075,\n",
       " 'p_value': 0.9999000099990001}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the metric and run the query\n",
    "WEAT().run_query(query_names, wefe_model, normalize=True, calculate_p_value=True, \n",
    "                 p_value_method=\"approximate\", p_value_iterations=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ce4a1",
   "metadata": {},
   "source": [
    "### 7.2.3 All gender-identifier words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c38e7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the query\n",
    "query_words = Query(\n",
    "    target_sets=[\n",
    "        female_words,\n",
    "        male_words,\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        academic_general + professional,\n",
    "        personal_information + physical_attributes\n",
    "    ],\n",
    "    target_sets_names=[\"Female Words\", \"Male Words\"],\n",
    "    attribute_sets_names=[\"Professional\", \"Personal\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "46241e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female Words and Male Words wrt Professional and Personal',\n",
       " 'result': -0.49194356167895925,\n",
       " 'weat': -0.49194356167895925,\n",
       " 'effect_size': -0.499921185807828,\n",
       " 'p_value': 0.8083191680831917}"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the metric and run the query\n",
    "WEAT().run_query(query_words, wefe_model, normalize=True, calculate_p_value=True, \n",
    "                 p_value_method=\"approximate\", p_value_iterations=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61009258",
   "metadata": {},
   "source": [
    "## 7.3 Run WEAT test on career and family words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "37889cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the query\n",
    "query_carfam = Query(\n",
    "    target_sets=[\n",
    "        female_words,\n",
    "        male_words,\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        career,\n",
    "        family\n",
    "    ],\n",
    "    target_sets_names=[\"Female terms\", \"Male Terms\"],\n",
    "    attribute_sets_names=[\"Career\", \"Family\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "3b80a431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male Terms wrt Career and Family',\n",
       " 'result': -0.39675114249500143,\n",
       " 'weat': -0.39675114249500143,\n",
       " 'effect_size': -0.7348252153789426,\n",
       " 'p_value': 0.8983101689831017}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance the metric and run the query\n",
    "WEAT().run_query(query_carfam, wefe_model, normalize=True, calculate_p_value=True, \n",
    "                 p_value_method=\"approximate\", p_value_iterations=10000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b5b29dab5abad7291a2796c34b065282e6e094f125ce0d0c0f2684a6be53937"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
